{
  "cells": [
    {
      "metadata": {
        "_uuid": "7f4433826f377d7075029346549f44864b87eb4c",
        "_cell_guid": "c555bfa8-b98e-4a64-93ef-a74636b95a9f",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nfrom pathlib import Path\nimport time\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.restoration import denoise_wavelet\nfrom skimage.feature import local_binary_pattern\nfrom sklearn import neighbors, linear_model\nfrom sklearn.neural_network import MLPClassifier\nimport cv2",
      "execution_count": 102,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "3ce419710a34b287ae5459cf06e63f39fa9e3c89",
        "_cell_guid": "ff9641d7-ecb4-417e-acfe-32de856ee7c7",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Feature Extration - Local Binary Pattern\ndef lbp_feature_extraction(im, n_points, radius, method):\n    im_gray = cv2.cvtColor(np.array(im), cv2.COLOR_RGB2GRAY)\n    lbp = local_binary_pattern(im_gray, n_points, radius, method)\n    # Features returned are the hisogram of resulting data from lbp algorithm\n    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, n_points + 3), range=(0, radius + 2), normed=True)\n    return hist",
      "execution_count": 103,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e2a12bdf79094486f5f33440f02f52a5535bb3c0",
        "_cell_guid": "665bf19f-1e2b-47cd-a0a1-cc673808e8cf",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Feature Extraction - Denoise Wavelets\ndef den_wavelets(im):\n    im_clean = denoise_wavelet(im)\n    noise = im - im_clean\n    return noise",
      "execution_count": 104,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f972fc1e45a15595fcb0d43b8e7a9ad0d44aaa91",
        "_cell_guid": "8d0068a4-76e5-4d23-93b8-428b33c25381",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def logistic_reg(data, target):\n    log = logistic.fit(data, target)\n    return log",
      "execution_count": 105,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "91b5ac11f3e492a933c1b625ad18fba2824db5ee",
        "_cell_guid": "baefba99-0555-440c-88f1-544ebd820832",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def neural_network():\n    pass",
      "execution_count": 106,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "68d3ca15199a8097a14e310a7767f8f2998c918c",
        "_cell_guid": "5052716e-08ca-4b62-8c41-205d5693e3bd",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "def k_nearest_neighbor():\n    pass",
      "execution_count": 107,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e2f22fbd2af0fad38afdd29d1e5915088a15c9d6",
        "_cell_guid": "c9406230-69f6-4b4f-9125-4ec5067c88ea",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "is_kaggle = True\n\n# Generating train and test path\nif is_kaggle:\n    input_path = Path('../input')\nelse:\n    input_path = Path('../input')\ntrain_path = input_path / 'train'\ntest_path = input_path / 'test'",
      "execution_count": 108,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "145cca5f8286bbbbe8a8617c818406f0e4a290b2",
        "_cell_guid": "9cfc24c9-bd9b-479e-877d-aeb906fb8f73",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Listing all directories in trainning path\ncameras = os.listdir(train_path)",
      "execution_count": 109,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "09608fd0ee7f21854981e1a184de9532340be117",
        "collapsed": true,
        "_cell_guid": "1b9c8199-f18d-4022-9382-e169811c5155",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Defining size of trainning\nsize_train = 0.8",
      "execution_count": 110,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7b8f7888f687bd04c34d5daafca4c22009671c77",
        "_cell_guid": "22c7e87e-9fde-40ef-a92d-a16bca32cf8c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Generating DataFrame of images and labes in the trainning and validation dataset\ntrain_images = []\nn_pictures = []\n\ncount = 0\n\nfor camera in cameras:\n    pic = len(os.listdir(train_path / camera))\n    n_pictures.append(pic)\n    for fname in sorted(os.listdir(train_path / camera)):\n            train_images.append((camera, fname))\ntrain = pd.DataFrame(train_images, columns=['camera', 'fname'])",
      "execution_count": 116,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "59e4c960dd5cba6122eaa715accf1374df90b0e7",
        "_cell_guid": "620c9e93-c615-444c-a564-39c603e25545",
        "collapsed": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Generating DataFrame of images and labes in the testing dataset\ntest_images = []\nfor fname in sorted(os.listdir(test_path)):\n    test_images.append(fname)\ntest = pd.DataFrame(test_images, columns=['fname'])",
      "execution_count": 117,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "37b04a8a4415f69631b53709c44434711560261e",
        "_cell_guid": "ae01e175-744a-4a78-b169-892cf091627f",
        "trusted": true
      },
      "cell_type": "code",
      "source": "'''# Procedure to mount feature vectors\ntrain_lbp = []\ntrain_wav = []\nvalid_lbp = []\nvalid_wav = []\ntrain_target = []\nvalid_target = []\n\nj = 0\n\nstart = time.time()\nfor camera in cameras:\n    print(\"Feature extraction: %s\"%(camera))\n    for i in range(n_pictures[j]):\n        print(\"Example %i\"%i, end = '\\r')\n        seg = train[train['camera'] == camera]\n        seg = seg.reset_index()\n        path_im = train_path / seg.at[i, 'camera'] / seg.at[i, 'fname']\n        bgr_image = cv2.imread(str(path_im))\n        rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n        im = cv2.resize(rgb_image, (32, 32))\n        if i < int(size_train*n_pictures[j]):\n            train_wav.append(den_wavelets(im))\n            train_lbp.append(lbp_feature_extraction(im, 24, 8, 'uniform'))\n            train_target.append(seg.at[0, 'camera'])\n        else:\n            valid_wav.append(den_wavelets(im))\n            valid_lbp.append(lbp_feature_extraction(im, 24, 8, 'uniform'))\n            valid_target.append(seg.at[0, 'camera'])\n    j += 1\n    print(\"Extraction finished!\\n\")\nend = time.time()\n\nprint('The time elapsed to extract all lbp features was: %.2f min'%((end-start)/60))'''",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Feature extraction: Samsung-Galaxy-Note3\nExtraction finished!\n\nFeature extraction: Sony-NEX-7\nExtraction finished!\n\nFeature extraction: Motorola-Droid-Maxx\nExtraction finished!\n\nFeature extraction: iPhone-4s\nExtraction finished!\n\nFeature extraction: HTC-1-M7\nExtraction finished!\n\nFeature extraction: Motorola-X\nExtraction finished!\n\nFeature extraction: iPhone-6\nExtraction finished!\n\nFeature extraction: Motorola-Nexus-6\nExtraction finished!\n\nFeature extraction: LG-Nexus-5x\nExtraction finished!\n\nFeature extraction: Samsung-Galaxy-S4\nExtraction finished!\n\nThe time elapsed to extract all lbp features was: 596.712909\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3177249bf36cedf70731e320260719bb0499420"
      },
      "cell_type": "code",
      "source": "train_wav = np.array(train_wav)\ntrain_wav = train_wav.reshape(np.shape(train_wav)[0],-1)\n\nvalid_wav = np.array(valid_wav)\nvalid_wav = valid_wav.reshape(np.shape(valid_wav)[0],-1)\n\n\n#Predicting using logistic regression\nlogistic = linear_model.LogisticRegression()\nprint('Logistic Regression')\nprint('LBP - Score: %.2f'%(logistic.fit(train_lbp, train_target).score(valid_lbp, valid_target)))\nprint('WAV - Score: %.2f'%(logistic.fit(train_wav, train_target).score(valid_wav, valid_target)))\n\n# Predicting using logistic regression\nknn = neighbors.KNeighborsClassifier()\nprint(\"(KNN) Score: %.2f\"%(knn.fit(train_lbp, train_target).score(valid_lbp, valid_target)))\n\n# Predicting using logistic regression\nmlp = MLPClassifier(alpha=1)\nprint(\"(MLP) Score: %.2f\"%(mlp.fit(train_lbp, train_target).score(valid_lbp, valid_target)))",
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Logistic Regression\nLBP - Score: 0.14\nWAV - Score: 0.20\n(KNN) Score: 0.13\n(MLP) Score: 0.12\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "ce94aded175568ad2f0ccad4defc3c3879e13bfc"
      },
      "cell_type": "code",
      "source": "# Tests\nseg = train[train['camera'] == cameras[1]]\nseg = seg.reset_index()\npath_im = train_path / seg.get_value(0, 'camera') / seg.get_value(120, 'fname')\nbgr_image = cv2.imread(str(path_im))\nrgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\nim = cv2.resize(rgb_image, (128, 128))\n#im = rgb_image\nim_gray = cv2.cvtColor(np.array(im), cv2.COLOR_RGB2GRAY)\nplt.imshow(im)\nplt.figure()\n#plt.imshow(rgb_image)\n\n#plt.imshow(im)\nnoise = den_wavelets(im)\nplt.figure()\nplt.imshow(np.round(noise))\n(fig, ax) = plt.subplots()\nprint(np.shape(noise))\nprint(np.shape(noise.ravel()))\nax.hist(np.round(noise).ravel(), normed=True, bins=20, range=(0,256))",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
